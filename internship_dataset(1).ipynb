{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df=pd.read_excel(\"../input/data_insta (1).xlsx\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#a=df[\"USERNAME\"]\n#a.to_csv(\"USERNAMES.csv\"r\"C:\\Users\\umairansari\\Desktop\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dropping the columns with more than 70% missing values\nlimit=len(df)*.70\ndf=df.dropna(thresh=limit,axis=1)\ndf.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop([\"LOCATION\",\"TEXT\",\"USERNAME\",\"TYPE(1 PHOTO,2 VIDEO)\",\"DAY(0 MONDAY,6 SUNDAY)\",\"NUMBER OF TAGS\",\"DATE\"],axis=1,inplace=True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#for counting hashtags\ndf[\"HASHTAG_COUNTS\"]=df[\"LIST OF TAGS\"].str.count('#')\ndf.drop([\"LIST OF TAGS\"],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lets drop the date column as date wont be effecting the likes and comments\ndf.drop([\"DATE\"],inplace=True,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create two lists for the loop results to be placed\n#lat = []\n#lon = []\n\n# For each row in a varible,\n#for row in df[\"LOCATION\"]:\n    # Try to,\n #   try:\n        # Split the row by comma, convert to float, and append\n        # everything before the comma to lat\n  #      lat.append(float(row.split(',')[0]))\n        # Split the row by comma, convert to float, and append\n        # everything after the comma to lon\n   #     lon.append(float(row.split(',')[1]))\n    # But if you get an error\n    #except:\n        # append a missing value to lat\n     #   lat.append(np.NaN)\n        # append a missing value to lon\n      #  lon.append(np.NaN)\n\n# Create two new columns from lat and lon\n#df['latitude'] = lat\n#df['longitude'] = lon","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#by default pd.getdummies funcition return one hot encoding and if we include drop first then it will create dummies for us\n#df1=pd.get_dummies(df[\"USERNAME\"],prefix_sep=\"_\")\n#df=pd.concat([df,df1],join=\"outer\",axis=1)\n#df.drop([\"USERNAME\"],axis=1,inplace=True)\n#df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#no package is working for reverseing the geolocation so we will try to use google apis for reverse geolocating\n#!pip install pygeocoder\n#import Geocoder\n# Convert longitude and latitude to a location\n#results = Geocoder.reverse_geocode(df['latitude'][0], df['longitude'][0])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing the requests for making api calls\nimport requests","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#making the new columns as this will store the data returned by the json object\n#df['geocode_data'] = ''\n#df['city'] = ''\n#df['country'] = ''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#defining a function to handle the api requests for reverse geocoding using google maps api as the packages are not working \n#sometimes the api is working and sometimes it is not working\n#def reverse_geocode(latlng):\n #   result = {}\n  #  url = 'https://maps.googleapis.com/maps/api/geocode/json?latlng={}'\n   # request = url.format(latlng)\n    #data = requests.get(request).json()\n    #if len(data['results']) > 0:\n    #    result = data['results'][0]\n    #return result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#making the new column for saving the location name\n#df['geocode_data'] = df['LOCATION'].map(reverse_geocode)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#filling the na values in location columns by 0 as there is n0 checkin for the following post\n#df[\"LOCATION\"].fillna(\"0\",inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#we are dropping the list of tags column as we know that there are the number of #tags used in the posts\n#df.drop([\"LIST OF TAGS\"],inplace=True,axis=1)\ndf[\"HASHTAG_COUNTS\"].fillna(0,inplace=True,axis=0)\ndf.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dropping the rows with na values\ndf.dropna(axis=0,how=\"any\",inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking the na values and the final dimensions of the data\ndf.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#counting the - symbols for data cleaning\n#for col in cat_col:\n #   print(x_train[col].str.count('-').sum(),col)\n    \n#imputing the - values with some meaningful form\n\n#if no of tags are - that means no tags are used for x_train and x_test\n#x_train[\"NUMBER OF TAGS\"]=x_train[\"NUMBER OF TAGS\"].str.replace(\"-\",\"0\")\n#x_train[\"DAY(0 MONDAY,6 SUNDAY)\"]=x_train[\"DAY(0 MONDAY,6 SUNDAY)\"].str.replace(\"-\",\"0\")\n#a=x_train[\"TYPE(1 PHOTO,2 VIDEO)\"].mode()\ndf[\"USERS IN PHOTO\"]=df[\"USERS IN PHOTO\"].str.replace(\"-\",\"0\")\n#x_train[\"TYPE(1 PHOTO,2 VIDEO)\"]=x_train[\"TYPE(1 PHOTO,2 VIDEO)\"].str.replace(\"-\",\"1\")\n\n#now for x_test\n\n#x_test[\"NUMBER OF TAGS\"]=x_test[\"NUMBER OF TAGS\"].str.replace(\"-\",\"0\")\n#x_test[\"DAY(0 MONDAY,6 SUNDAY)\"]=x_test[\"DAY(0 MONDAY,6 SUNDAY)\"].str.replace(\"-\",\"0\")\n#a=x_train[\"TYPE(1 PHOTO,2 VIDEO)\"].mode()\n#x_test[\"USERS IN PHOTO\"]=x_test[\"USERS IN PHOTO\"].str.replace(\"-\",\"0\")\n#x_test[\"TYPE(1 PHOTO,2 VIDEO)\"]=x_test[\"TYPE(1 PHOTO,2 VIDEO)\"].str.replace(\"-\",\"1\")\n\n#\n#x_test[\"NUMBER OF TAGS\"]=x_test[\"NUMBER OF TAGS\"].str.replace(\"//\",\"0\")\n#x_train[\"NUMBER OF TAGS\"]=x_train[\"NUMBER OF TAGS\"].str.replace(\"//\",\"0\")\n#x_test[\"DAY(0 MONDAY,6 SUNDAY)\"]=x_test[\"DAY(0 MONDAY,6 SUNDAY)\"].str.replace(\"//\",\"0\")\n\n#x_train[\"DAY(0 MONDAY,6 SUNDAY)\"]=x_train[\"DAY(0 MONDAY,6 SUNDAY)\"].str.replace(\"//\",\"0\")\n\n\n#x_test[\"NUMBER OF TAGS\"]=x_test[\"NUMBER OF TAGS\"].str.replace(\"\\\\\",\"0\")\n#x_train[\"NUMBER OF TAGS\"]=x_train[\"NUMBER OF TAGS\"].str.replace(\"\\\\\",\"0\")\n#x_test[\"DAY(0 MONDAY,6 SUNDAY)\"]=x_test[\"DAY(0 MONDAY,6 SUNDAY)\"].str.replace(\"\\\\\",\"0\")\n\n#x_train[\"DAY(0 MONDAY,6 SUNDAY)\"]=x_train[\"DAY(0 MONDAY,6 SUNDAY)\"].str.replace(\"\\\\\",\"0\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#cleaning the irratonal values from both the test and train dataset by dropping the rows on th basis of its values\ndf=df[df[\"USERS IN PHOTO\"] != ' Akti Vasiliadi, Silo building \\\\']\n\ndf=df[df[\"USERS IN PHOTO\"] != ' Πύλη Ε2 \\\\']\n\ndf=df[df[\"USERS IN PHOTO\"] != ' 18: 00021: 30 \\\\']\n#x_train=x_train[x_train[\"NUMBER OF TAGS\"] != ' VASISTAS Theatre Group & Argyro Chioti 0']\n#x_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now we will check the type of the data we have\n\ndf[\"USERS IN PHOTO\"]=df[\"USERS IN PHOTO\"].astype(\"float\")\n#counting the (-) symbols for data cleaning\ndf.info()\n\ndf[\"USERS IN PHOTO\"].fillna(0,inplace=True,axis=0)\ndf.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train,test=train_test_split(df,test_size=.25,random_state=43)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.reset_index(),test.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape,test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train=train.drop([\"LINK\"],axis=1)\ny_train=train[\"LIKES\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test=test.drop([\"LINK\"],axis=1)\ny_test=test[\"LIKES\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.shape,y_train.shape\n\nx_test.shape,y_test.shape\n\n\n#counting the number of (-) symbols in the final data\n#for col in cat_col:\n #   print(x_train[col].str.count('-').sum(),col)\n    \n#for col in cat_col:\n #   print(x_train[col].str.count('//').sum(),col)\n\n    \n#we dont have any \\\\ in the df\n#for col in cat_col:\n #   print(x_train[col].str.count('\\\\').sum(),col)\n    \n#similarly checking for x_test\n#for col in cat_col:\n #   print(x_test[col].str.count('-').sum(),col)\n    \n#for col in cat_col:\n #   print(x_test[col].str.count('//').sum(),col)\n\n\n    \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#changing the type of the columns\n#cat_col=x_train.select_dtypes(\"object\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.isna().sum(),x_test.isna().sum()\n#x_train[\"NUMBER OF TAGS\"].fillna(0,axis=0,inplace=True)\n#x_train[\"USERS IN PHOTO\"].fillna(0,axis=0,inplace=True)\n#x_train[\"HASHTAG_COUNTS\"].fillna(0,axis=0,inplace=True)\n\n#x_test[\"NUMBER OF TAGS\"].fillna(0,axis=0,inplace=True)\n#x_test[\"USERS IN PHOTO\"].fillna(0,axis=0,inplace=True)\n#x_test[\"HASHTAG_COUNTS\"].fillna(0,axis=0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now changing the type of the columns so that our models can understand from the data\n#for col in cat_col:\n #   x_train[col]=x_train[col].astype(\"float\")\n#for col in cat_col:\n #   x_test[col]=x_test[col].astype(\"float\")\n#x_train.columns,x_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.columns,x_test.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#x_train[\"USERS IN PHOTO\"]=x_train[\"USERS IN PHOTO\"].fillna(0,axis=0)\n#x_test[\"USERS IN PHOTO\"]=x_test[\"USERS IN PHOTO\"].fillna(0,axis=0)\n#print(x_test.isna().sum())\n\n#x_test.shape\n#x_train.columns,x_train.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error,r2_score\nfrom sklearn.model_selection import GridSearchCV,RandomizedSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.isna().sum(),y_test.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lin_reg=LinearRegression()\nlin_reg.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_linear=lin_reg.predict(x_test)\npred_linear","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now checking the r2 score of linear model\nmean_squared_error(y_test,pred_linear)\nr2_score(y_test,pred_linear)\n#we can see that out linear model is generalizing well as compared to the other models like SVM and RF","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_model=RandomForestRegressor()\nrf_model.fit(x_train,y_train)\nrf_predicted=rf_model.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now checking the r2score on rf model\n#mean_squared_error(y_test,rf_predicted)\nr2_score(y_test,rf_predicted)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVR","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now checking the r2 score on SVM regressor\nSVR_model=SVR()\nSVR_model.fit(x_train,y_train)\nSVR_predicted=SVR_model.predict(x_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_squared_error(y_test,SVR_predicted)\nr2_score(y_test,SVR_predicted)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsRegressor \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"knn_model=KNeighborsRegressor()\nknn_model.fit(x_train,y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now checking the r2 score on KNN regressor\n#mean_squared_error(y_test,knn_predicted)\nr2_score(y_test,knn_model.predict(x_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#we are using XGboost without random forest\n#we can also use various techinques like SGD,Gradient descent,Adaboost\nfrom xgboost import XGBRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xg_model=XGBRegressor()\nxg_model.fit(x_train,y_train)\nr2_score(y_test,xg_model.predict(x_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\n#using hyperparameter tuning in xgboost\n#param_test1 = {\n#'max_depth':[2,3,4],\n# 'n_estimators':[2,4,6],\n #'min_child_weight':[4,5,6]\n# 'max_depth':np.arange(3,10,2),\n# 'min_child_weight':np.arange(1,6,2)\n#}\n#grid_serach1 = GridSearchCV(estimator = xgb.XGBRegressor( learning_rate =0.1, n_estimators=6, max_depth=5,\n #min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n #objective= 'reg:linear', nthread=4, scale_pos_weight=1, seed=27), \n #param_grid = param_test1, scoring='neg_mean_squared_error',n_jobs=4,iid=False, cv=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fitting the model now with grid search parameters\n#we can also use parameter tuning with randomized search cv and for other models too\n#grid_serach1.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"NOW LETS SAVE THE MODEL"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\n# Save the trained model as a pickle string. \nsaved_model = pickle.dumps(lin_reg) \n  \n# Load the pickled model \nlreg_from_pickle = pickle.loads(saved_model) \n  \n# Use the loaded pickled model to make predictions \nlreg_from_pickle.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#loading the dataset for submission\nx_test.shape,y_test.shape,test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f=test[\"LINK\"]\nsubmission1=pd.DataFrame([f])\nsubmission=pd.DataFrame([pred_linear])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#final predictions with images\nfd=pd.concat([submission,submission1],ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fd","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}